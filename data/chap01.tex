% !TeX root = ../thuthesis-example.tex

\chapter{课题背景与意义}

% 研究生学位论文撰写，除表达形式上需要符合一定的格式要求外，内容方面上也要遵循一些共性原则。

% 通常研究生学位论文只能有一个主题（不能是几块工作拼凑在一起），该主题应针对某学科领域中的一个具体问题展开深入、系统的研究，并得出有价值的研究结论。
% 学位论文的研究主题切忌过大，例如，“中国国有企业改制问题研究”这样的研究主题过大，因为“国企改制”涉及的问题范围太广，很难在一本研究生学位论文中完全研究透彻。



\section{具身移动操作的研究背景}

具身移动操作（Embodied Mobile Manipulation）的核心目标是在真实或高保真拟真环境中实现“感知—理解—规划—控制”的闭环，
使智能体能够依据自然语言或任务指令自主完成各种操作任务。这通常需要机器人具备完备的环境感知与理解，并根据任务类型和操作空间范围实现自主移动与操作规划。
在面向实际通用场景（如家庭、实验室与仓储）中，操作任务并非单一的导航或单一的操作，而是先在未知或半未知空间中移动到合理的语义上下文（例如工作台、目标设备或特定区域），继而完成各种如抓取、开关、插拔、放置等精细动作。
因此，面向通用的具身移动操作，更要求机器人在各种复杂场景下，实现稳定的任务执行，并具备跨任务与跨环境的泛化能力、对感知噪声与动态扰动的不敏感与鲁棒性，
以及在语义指令驱动下将导航与精细操作一体化闭环（如主动感知、约束安全与失败恢复）的能力。

近年来，基于通用模型(Foundation Model)驱动的具身移动和操作分别取得了有效的进展。
在移动方面，视觉-语言-导航(Visual-Language-Navigation, VLN)在从语言到可达目标的路径规划方面实现了丰富的积累，在仿真和真机中呈现出令人印象深刻的效果；
同时，无论是基于模仿学习(Imitation Learning, IL)还是离线强化学习(Offline Reinforcement Learning, RL)的操作方法，在对象识别、姿态估计、抓取规划等方面都取得了显著的进展，并在真实机器人平台上得到了验证。
然而，在移动操作任务中，移动和操作之间存在不可忽视的强耦合：
移动阶段所形成的视角、距离与遮挡关系直接决定了后续操作的观测质量与可达性，
而操作对目标物体、姿态与约束的先验又会反过来影响移动的策略选择与路径代价。
因此，仅在导航或操作单一子任务上取得进展，并不足以保证端到端任务的成功率、稳定性与泛化能力。

与此同时，以视觉-语言-动作（Visual-Language-Action, VLA）为代表的大模型在指令理解、情景推理与跨任务迁移上展现出统一表达与泛化能力，
通过将开放式语言意图与感知结果对齐为可执行中间表示并生成带约束的分层技能序列，从而支撑“从语言到动作”的一体化规划与在动态噪声下的鲁棒重规划，
为“从语言到可执行子目标与技能序列”的一体化规划提供了新的可行性。
因此，如何将大模型的语义优势落地为低层可控、可验证的移动与操作策略，并在扰动与不确定条件下保持鲁棒，是当前研究的重要方向。


\section{课题来源}

近年来，随着服务机器人、实验室助理机器人等应用的推进，机器人在室内环境中“既能自主移动，又能完成抓取、放置、开关等操作”的需求逐渐增加。
无论是在家居、办公室，还是在实验室等典型室内场景中，机器人往往需要先在环境中移动到合适的位置，再对目标物体或设备执行相应操作，
这类“具身移动操作”任务逐渐成为智能机器人研究中的一个重要方向。
与此同时，多模态基础模型和视觉-语言-动作大模型的发展，使得机器人有可能在同一模型框架下处理视觉、语言与动作信息，
从自然语言指令出发完成环境理解和行为生成，这为改进现有移动操作方法提供了新的思路。

然而，现有很多工作要么只关注固定机械臂的操作，要么只针对局部、小范围的导航任务；即便有部分移动操作系统可以完成端到端任务，
其方法多半针对特定场景或特定任务进行定制，对视觉、语言与动作的统一建模和可扩展性仍然有限。
在这种背景下，围绕“基于视觉-语言-动作大模型的具身移动操作方法”开展研究，一方面可以呼应当前多模态大模型在机器人领域落地的趋势，
另一方面也有助于提升机器人在典型通用场景中的任务执行能力。

本课题“面向通用场景的基于视觉-语言-动作大模型的具身移动操作方法研究”主要面向各类通用场景（如家庭、实验室与仓储等）中具有代表性的移动操作任务，
重点关注如何利用视觉-语言-动作大模型统一处理指令理解、环境感知和移动/操作决策问题。课题的提出一方面源于当前具身智能与大模型结合的研究动向，
另一方面也基于前期在视觉-语言导航（VLN）和具身操作方面已有的算法和系统积累，
希望在此基础上进一步探索一种具有一定通用性、但仍然可控可实现的具身移动操作方法。


\section{具身移动操作方法的研究意义}

从学术研究角度看，围绕“面向通用场景的基于视觉-语言-动作大模型的具身移动操作方法”开展系统研究，有望在以下几个方面形成有价值的探索：
一是通过引入统一的中间表示，将自然语言指令、环境语义信息与可执行动作在同一框架下对齐，为移动与操作的协同规划提供更清晰的语义—几何映射途径；
二是基于视觉-语言-动作大模型，将指令理解、情景推理与技能序列生成结合起来，探索从“语言—感知—动作”的端到端一体化方法，为具身智能中高层语义推理与低层控制之间的连接提供新的思路；
三是面向典型通用场景，系统分析移动与操作强耦合带来的问题，设计相应的鲁棒策略与评测指标，为今后更大规模、更复杂场景下的具身移动操作研究打下方法和系统基础。

从应用需求角度看，本课题的研究有望为实验室助理机器人、物流仓储机器人乃至面向家居服务机器人的具身移动操作任务提供可落地的技术方案。
通过提升机器人在通用场景中的整体能力，可以在一定程度上减少对场景的人工改造与精细规则设计，降低系统部署和维护成本。
同时，得益于视觉-语言-动作大模型的统一建模能力，所提出的方法在后续扩展到新任务、新物体或新环境时，具有更好的可迁移性和可扩展性。


