@article{Yao2023MobileNavCN,
  author    = {姚陈鹏 and 石文博 and 刘成菊 and 等},
  title     = {移动机器人导航技术综述},
  journal   = {中国科学: 信息科学},
  volume    = {53},
  number    = {12},
  pages     = {2303--2324},
  year      = {2023},
  issn      = {1674-7267}
}

@article{Abdulsaheb2023Classical,
  author    = {Abdulsaheb, Jaafar Ahmed and Kadhim, Dheyaa Jasim},
  title     = {Classical and heuristic approaches for mobile robot path planning: A survey},
  journal   = {Robotics},
  volume    = {12},
  number    = {4},
  pages     = {93},
  year      = {2023},
  publisher = {MDPI}
}

@article{Wang2025LLMEmbodiedSysCN,
  author  = {王文晟 and 谭宁 and 黄凯 and 等},
  title   = {基于大模型的具身智能系统综述},
  journal = {自动化学报},
  volume  = {51},
  number  = {1},
  pages   = {1--19},
  year    = {2025},
  issn    = {0254-4156}
}

@article{Wu2024EmbodiedNavSurvey,
  author    = {Wu, Yuchen and Zhang, Pengcheng and Gu, Meiying and {\textit{et al.}}},
  title     = {Embodied navigation with multi-modal information: A survey from tasks to methodology},
  journal   = {Information Fusion},
  volume    = {112},
  pages     = {102532},
  year      = {2024},
  publisher = {Elsevier}
}

@article{Gao2025EMLM,
  author    = {高超 and 杨莹 and 陈世超 and 等},
  title     = {多模态模型驱动的具身智能研究综述},
  journal   = {智能感知工程},
  volume    = {2},
  number    = {2},
  pages     = {1--12},
  year      = {2025},
  issn      = {2097-4965}
}

@article{Krantz2022InstanceImageNav,
  title   = {Instance-Specific Image Goal Navigation: Training Embodied Agents to Find Object Instances},
  author  = {Krantz, Jacob and Maksymets, Oleksandr and Gokaslan, Aaron and {\textit{et al.}}},
  journal = {arXiv preprint arXiv:2211.15876},
  year    = {2022}
}

@article{Zhang2024VLNFM,
  author    = {Zhang, Yue and Ma, Ziqiao and Li, Jialu and {\textit{et al.}}},
  title     = {Vision-and-language navigation today and tomorrow: A survey in the era of foundation models},
  journal   = {arXiv preprint arXiv:2407.07035},
  year      = {2024}
}

@article{Huang2022MultiModalSensorFusion,
  author    = {Huang, Keli and Shi, Botian and Li, Xiang and {\textit{et al.}}},
  title     = {Multi-modal sensor fusion for auto driving perception: A survey},
  journal   = {arXiv preprint arXiv:2202.02703},
  year      = {2022}
}

@article{Zhang2020MultiModalSensorFusion,
  author    = {张燕咏 and 张莎 and 张昱 and 等},
  title     = {基于多模态融合的自动驾驶感知及计算},
  journal   = {计算机研究与发展},
  volume    = {57},
  number    = {9},
  pages     = {1781--1799},
  year      = {2020},
  issn      = {1000-1239}
}

@article{Han2023DRLManip,
  author    = {Han, Dong and Mulyana, Beni and Stankovic, Vladimir and {\textit{et al.}}},
  title     = {A survey on deep reinforcement learning algorithms for robotic manipulation},
  journal   = {Sensors},
  volume    = {23},
  number    = {7},
  pages     = {3762},
  year      = {2023},
  publisher = {MDPI}
}

@article{Celemin2022IILSurvey,
  author    = {Celemin, Carlos and P{\'e}rez-Dattari, Rodrigo and Chisari, Eugenio and {\textit{et al.}}},
  title     = {Interactive imitation learning in robotics: A survey},
  journal   = {Foundations and Trends{\textregistered} in Robotics},
  volume    = {10},
  number    = {1-2},
  pages     = {1--197},
  year      = {2022},
  publisher = {Now Publishers, Inc.}
}

@article{Levine2016EndToEndVisuomotor,
  author    = {Levine, Sergey and Finn, Chelsea and Darrell, Trevor and {\textit{et al.}}},
  title     = {End-to-end training of deep visuomotor policies},
  journal   = {Journal of Machine Learning Research},
  volume    = {17},
  number    = {39},
  pages     = {1--40},
  year      = {2016}
}

@article{Chi2025DiffusionPolicy,
  author    = {Chi, Cheng and Xu, Zhenjia and Feng, Siyuan and {\textit{et al.}}},
  title     = {Diffusion policy: Visuomotor policy learning via action diffusion},
  journal   = {The International Journal of Robotics Research},
  volume    = {44},
  pages     = {1684--1704},
  year      = {2025},
  publisher = {Sage Publications Sage UK: London, England}
}

@article{Ze20243DPolicy,
  author    = {Ze, Yanjie and Zhang, Gu and Zhang, Kangning and {\textit{et al.}}},
  title     = {3d diffusion policy: Generalizable visuomotor policy learning via simple 3d representations},
  journal   = {arXiv preprint arXiv:2403.03954},
  year      = {2024}
}

@article{Fu2024MobileAloha,
  author    = {Fu, Zipeng and Zhao, Tony Z and Finn, Chelsea},
  title     = {Mobile aloha: Learning bimanual mobile manipulation with low-cost whole-body teleoperation},
  journal   = {arXiv preprint arXiv:2401.02117},
  year      = {2024}
}

@article{Liu2025AligningCyberSpace,
  author    = {Liu, Yang and Chen, Weixing and Bai, Yongjie and {\textit{et al.}}},
  title     = {Aligning Cyber Space With Physical World: A Comprehensive Survey on Embodied AI}, 
  journal   = {IEEE/ASME Transactions on Mechatronics},
  volume    = {30},
  number    = {3},
  pages     = {1--22},
  year      = {2025},
  publisher = {IEEE}
}

@article{Ma2024Survey,
  author    = {Ma, Yueen and Song, Zixing and Zhuang, Yuzheng and {\textit{et al.}}},
  title     = {A survey on vision-language-action models for embodied ai},
  journal   = {arXiv preprint arXiv:2405.14093},
  year      = {2024}
}

@article{Xiao2025Robot,
  title     = {Robot learning in the era of foundation models: A survey},
  author    = {Xiao, Xuan and Liu, Jiahang and Wang, Zhipeng and {\textit{et al.}}},
  journal   = {Neurocomputing},
  pages     = {129963},
  year      = {2025},
  publisher = {Elsevier}
}

@article{Thakar2023Survey,
  author    = {Thakar, Shantanu and Srinivasan, Srivatsan and Al-Hussaini, Sarah and {\textit{et al.}}},
  title     = {A survey of wheeled mobile manipulation: A decision-making perspective},
  journal   = {Journal of Mechanisms and Robotics},
  volume    = {15},
  number    = {2},
  pages     = {020801},
  year      = {2023},
  publisher = {ASME}
}

@article{Ahn2022SayCan,
  author    = {Ahn, Michael and Brohan, Anthony and Brown, Noah and {\textit{et al.}}},
  title     = {Do as i can, not as i say: Grounding language in robotic affordances},
  journal   = {arXiv preprint arXiv:2204.01691},
  year      = {2022}
}

@article{Brohan2022RT1,
  author    = {Brohan, Anthony and Brown, Noah and Carbajal, Justice and {\textit{et al.}}},
  title     = {Rt-1: Robotics transformer for real-world control at scale},
  journal   = {arXiv preprint arXiv:2212.06817},
  year      = {2022},
}

@article{Driess2023PALME,
  author    = {Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and {\textit{et al.}}},
  title     = {Palm-e: An embodied multimodal language model},
  journal   = {arXiv preprint arXiv:2303.17580},
  year      = {2023}
}

@article{Kim2024OpenVLA,
  author    = {Kim, Moo Jin and Pertsch, Karl and Karamcheti, Siddharth and {\textit{et al.}}},
  title     = {Openvla: An open-source vision-language-action model},
  journal   = {arXiv preprint arXiv:2406.09246},
  year      = {2024}
}

@article{Liang2022CodeAsPolicies,
  author    = {Liang, Jacky and Huang, Wenlong and Xia, Fei and {\textit{et al.}}},
  title     = {Code as policies: Language model programs for embodied control},
  journal   = {arXiv preprint arXiv:2209.07753},
  year      = {2022}
}

@article{Intelligence2025pi_05,
  author    = {Intelligence, Physical and Black, Kevin and Brown, Noah and {\textit{et al.}}},
  title     = {$\pi_{0.5}$: a Vision-Language-Action Model with Open-World Generalization},
  journal   = {arXiv preprint arXiv:2504.16054},
  year      = {2025}
}

@article{Zhong2025Survey,
  author    = {Zhong, Yifan and Bai, Fengshuo and Cai, Shaofei and {\textit{et al.}}},
  title     = {A Survey on Vision-Language-Action Models: An Action Tokenization Perspective},
  journal   = {arXiv preprint arXiv:2507.01925},
  year      = {2025}
}

@article{Team2025GeminiRobotics,
  author    = {Team, Gemini Robotics and {\textit{et al.}}},
  title     = {Gemini robotics: Bringing ai into the physical world},
  journal   = {arXiv preprint arXiv:2503.20020},
  year      = {2025}
}

@article{James2020RLBench,
  author    = {James, Stephen and Ma, Zicong and Arrojo, David Rovick and Davison, Andrew J},
  title     = {Rlbench: The robot learning benchmark \& learning environment},
  journal   = {IEEE Robotics and Automation Letters},
  volume    = {5},
  number    = {2},
  pages     = {3019--3026},
  year      = {2020},
  publisher = {IEEE}
}

@article{Gu2023ManiSkill2,
  author    = {Gu, Jiayuan and Xiang, Fanbo and Li, Xuanlin and Ling, Zhan and Liu, Xiqiang and Mu, Tongzhou and Tang, Yihe and Tao, Stone and Wei, Xinyue and Yao, Yunchao and {\textit{et al.}}},
  title     = {Maniskill2: A unified benchmark for generalizable manipulation skills},
  journal   = {arXiv preprint arXiv:2302.04659},
  year      = {2023}
}

@article{Mees2022CALVIN,
  author    = {Mees, Oier and Hermann, Lukas and Rosete-Beas, Erick and Burgard, Wolfram},
  title     = {Calvin: A benchmark for language-conditioned policy learning for long-horizon robot manipulation tasks},
  journal   = {IEEE Robotics and Automation Letters},
  volume    = {7},
  number    = {3},
  pages     = {7327--7334},
  year      = {2022},
  publisher = {IEEE}
}

@article{Liu2023Libero,
  author    = {Liu, Bo and Zhu, Yifeng and Gao, Chongkai and Feng, Yihao and Liu, Qiang and Zhu, Yuke and Stone, Peter},
  title     = {Libero: Benchmarking knowledge transfer for lifelong robot learning},
  journal   = {Advances in Neural Information Processing Systems},
  volume    = {36},
  pages     = {44776--44791},
  year      = {2023}
}

@article{Szot2021Habitat,
  author    = {Szot, Andrew and Clegg, Alexander and Undersander, Eric and Wijmans, Erik and Zhao, Yili and Turner, John and Maestre, Noah and Mukadam, Mustafa and Chaplot, Devendra Singh and Maksymets, Oleksandr and {\textit{et al.}}},
  title     = {Habitat 2.0: Training home assistants to rearrange their habitat},
  journal   = {Advances in neural information processing systems},
  volume    = {34},
  pages     = {251--266},
  year      = {2021}
}

@article{Li2021iGibson,
  author    = {Li, Chengshu and Xia, Fei and Mart{\'\i}n-Mart{\'\i}n, Roberto and Lingelbach, Michael and Srivastava, Sanjana and Shen, Bokui and Vainio, Kent and Gokmen, Cem and Dharan, Gokul and Jain, Tanish and {\textit{et al.}}},
  title     = {igibson 2.0: Object-centric simulation for robot learning of everyday household tasks},
  journal   = {arXiv preprint arXiv:2108.03272},
  year      = {2021}
}

@article{Yenamandra2023Homerobot,
  author    = {Yenamandra, Sriram and Ramachandran, Arun and Yadav, Karmesh and Wang, Austin and Khanna, Mukul and Gervet, Theophile and Yang, Tsung-Yen and Jain, Vidhi and Clegg, Alexander William and Turner, John and {\textit{et al.}}},
  title     = {Homerobot: Open-vocabulary mobile manipulation},
  journal   = {arXiv preprint arXiv:2306.11565},
  year      = {2023}
}

@article{Jaafar2024LaNMP,
  author    = {Jaafar, Ahmed and Raman, Shreyas Sundara and Wei, Yichen and Juliani, Sofia and Wernerfelt, Anneke and Quartey, Benedict and Idrees, Ifrah and Liu, Jason Xinyu and Tellex, Stefanie and {\textit{et al.}}},
  title     = {Lanmp: A language-conditioned mobile manipulation benchmark for autonomous robots},
  journal   = {arXiv preprint arXiv:2412.05313},
  year      = {2024}
}

@article{Zhu2020RoboSuite,
  author    = {Zhu, Yuke and Wong, Josiah and Mandlekar, Ajay and Mart{\'\i}n-Mart{\'\i}n, Roberto and Joshi, Abhishek and Nasiriany, Soroush and Zhu, Yifeng},
  title     = {Robosuite: A modular simulation framework and benchmark for robot learning},
  journal   = {arXiv preprint arXiv:2009.12293},
  year      = {2020}
}

@article{Makoviychuk2021IsaacGym,
  author    = {Makoviychuk, Viktor and Wawrzyniak, Lukasz and Guo, Yunrong and Lu, Michelle and Storey, Kier and Macklin, Miles and Hoeller, David and Rudin, Nikita and Allshire, Arthur and Handa, Ankur and {\textit{et al.}}},
  title     = {Isaac gym: High performance gpu-based physics simulation for robot learning},
  journal   = {arXiv preprint arXiv:2108.10470},
  year      = {2021}
}


@inproceedings{Chaplot2020SemExp,
  author    = {Chaplot, Devendra Singh and Gandhi, Dhiraj Prakashchand and Gupta, Abhinav and {\textit{et al.}}},
  title     = {Object Goal Navigation using Goal-Oriented Semantic Exploration},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  editor    = {Larochelle, H. and Ranzato, M. and Hadsell, R. and Balcan, M.F. and Lin, H.},
  pages     = {4247--4258},
  year      = {2020},
  publisher = {Curran Associates, Inc.},
}

@inproceedings{Anderson2018VLNR2R,
  author    = {Anderson, Peter and Wu, Qi and Teney, Damien and {\textit{et al.}}},
  title     = {Vision-and-Language Navigation: Interpreting Visually-Grounded Navigation Instructions in Real Environments},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2018},
  publisher = {IEEE Computer Society}
}

@inproceedings{Gu2022VLNSurvey,
  author    = {Gu, Jing and Stefani, Eliana and Wu, Qi and {\textit{et al.}}},
  title     = {Vision-and-Language Navigation: A Survey of Tasks, Methods, and Future Directions},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (ACL)},
  year      = {2022},
  address   = {Dublin, Ireland},
  publisher = {Association for Computational Linguistics}
}

@inproceedings{Savva2019Habitat,
  author    = {Savva, Manolis and Kadian, Abhishek and Maksymets, Oleksandr and {\textit{et al.}}},
  title     = {Habitat: A Platform for Embodied AI Research},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  address   = {Seoul, Korea},
  year      = {2019},
  publisher = {IEEE Computer Society}
}

@inproceedings{McCormac2017SemanticFusion,
  author    = {McCormac, John and Handa, Ankur and Davison, Andrew and {\textit{et al.}}},
  title     = {SemanticFusion: Dense 3D semantic mapping with convolutional neural networks},
  booktitle = {Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)},
  year      = {2017},
  pages     = {4628--4635},
  publisher = {IEEE}
}

@inproceedings{Narita2019PanopticFusion,
  author    = {Narita, Gaku and Seno, Takashi and Ishikawa, Tomoya and {\textit{et al.}}},
  title     = {PanopticFusion: Online Volumetric Semantic Mapping at the Level of Stuff and Things},
  booktitle = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year      = {2019},
  pages     = {4205--4212},
  publisher = {IEEE}
}

@inproceedings{Dai2017ScanNet,
  author    = {Dai, Angela and Chang, Angel X. and Savva, Manolis and {\textit{et al.}}},
  title     = {ScanNet: Richly-Annotated 3D Reconstructions of Indoor Scenes},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2017},
  pages     = {2432--2443},
  publisher = {IEEE}
}

@inproceedings{Chang2017Matterport3D,
  author    = {Chang, Angel and Dai, Angela and Funkhouser, Thomas and {\textit{et al.}}},
  title     = {Matterport3D: Learning from RGB-D Data in Indoor Environments},
  booktitle = {Proceedings of the International Conference on 3D Vision (3DV)},
  year      = {2017},
  pages     = {667--676},
  publisher = {IEEE}
}

@inproceedings{Peng2023OpenScene,
  author    = {Peng, Songyou and Genova, Kyle and Jiang, Chiyu and {\textit{et al.}}},
  title     = {OpenScene: 3D Scene Understanding with Open Vocabularies},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2023},
  pages     = {815--824},
  publisher = {IEEE}
}

@inproceedings{He2024UniMOV3D,
  author    = {He, Qingdong and Peng, Jinlong and Jiang, Zhengkai and {\textit{et al.}}},
  title     = {UniM-OV3D: uni-modality open-vocabulary 3D scene understanding with fine-grained feature representation},
  booktitle = {Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence (IJCAI)},
  year      = {2024},
  pages     = {821--829},
  publisher = {IJCAI}
}

@inproceedings{Werby2024HierarchicalOV3DSG, 
  author    = {Werby, Abdelrhman and Huang, Chenguang and Büchner, Martin and {\textit{et al.}}}, 
  title     = {Hierarchical Open-Vocabulary 3D Scene Graphs for Language-Grounded Robot Navigation},
  booktitle = {Proceedings of Robotics: Science and Systems},
  year      = {2024},
  address   = {Delft, Netherlands},
  publisher = {RSS}
}

@inproceedings{Kalashnikov2018Scalable,
  author    = {Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and {\textit{et al.}}},
  title     = {Scalable deep reinforcement learning for vision-based robotic manipulation},
  booktitle = {Conference on robot learning},
  year      = {2018},
  publisher = {PMLR},
  pages     = {651--673}
}

@inproceedings{Jang2022BCZ,
  author    = {Jang, Eric and Irpan, Alex and Khansari, Mohi and {\textit{et al.}}},
  title     = {Bc-z: Zero-shot task generalization with robotic imitation learning},
  booktitle = {Conference on Robot Learning},
  year      = {2022},
  publisher = {PMLR},
  pages     = {991--1002}
}

@inproceedings{Huang2023SkillTransformer,
  author    = {Huang, Xiaoyu and Batra, Dhruv and Rai, Akshara and {\textit{et al.}}},
  title     = {Skill transformer: A monolithic policy for mobile manipulation},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year      = {2023},
  pages     = {10852--10862},
  publisher = {IEEE}
}

@inproceedings{Fu2023Deep,  
  author    = {Fu, Zipeng and Cheng, Xuxin and Pathak, Deepak},
  title     = {Deep whole-body control: learning a unified policy for manipulation and locomotion},
  booktitle = {Conference on Robot Learning},
  year      = {2023},
  pages     = {138--149},
  publisher = {PMLR}
}

@inproceedings{Shridhar2022CLIPORT,
  author    = {Shridhar, Mohit and Manuelli, Lucas and Fox, Dieter},
  title     = {Cliport: What and where pathways for robotic manipulation},
  booktitle = {Conference on robot learning},
  year      = {2022},
  pages     = {894--906},
  publisher = {PMLR}
}

@inproceedings{Shridhar2023PERACT,
  author    = {Shridhar, Mohit and Manuelli, Lucas and Fox, Dieter},
  title     = {Perceiver-actor: A multi-task transformer for robotic manipulation},
  booktitle = {Conference on Robot Learning},
  year      = {2023},
  pages     = {785--799},
  publisher = {PMLR}
}

@inproceedings{Jiang2023VIMA,
  author    = {Jiang, Yunfan and Gupta, Agrim and Zhang, Zichen and {\textit{et al.}}},
  title     = {VIMA: General Robot Manipulation with Multimodal Prompts},
  booktitle = {Fortieth International Conference on Machine Learning},
  year      = {2023},
  publisher = {PMLR}
}

@inproceedings{Zitkovich2023RT2,
  author    = {Zitkovich, Brianna and Yu, Tianhe and Xu, Sichun and {\textit{et al.}}},
  title     = {Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  booktitle = {Conference on Robot Learning},
  year      = {2023},
  pages     = {2165--2183},
  publisher = {PMLR}
}

@inproceedings{ONeill2024OpenXEmbodiment,
  author    = {O'Neill, Abby and Rehman, Abdul and Maddukuri, Abhiram and {\textit{et al.}}},
  title     = {Open X-Embodiment: Robotic Learning Datasets and RT-X Models : Open X-Embodiment Collaboration},
  booktitle = {2024 IEEE International Conference on Robotics and Automation (ICRA)}, 
  year      = {2024},
  pages     = {6892-6903},
  publisher = {IEEE}
}

@inproceedings{Wu2025MoManipVLA,
  author    = {Wu, Zhenyu and Zhou, Yuheng and Xu, Xiuwei and {\textit{et al.}}},
  title     = {Momanipvla: Transferring vision-language-action models for general mobile manipulation},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2025},
  pages     = {1714--1723},
  publisher = {IEEE Computer Society}
}

@inproceedings{Yu2020MetaWorld,
  author    = {Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  title     = {Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning},
  booktitle = {Conference on robot learning},
  year      = {2020},
  pages     = {1094--1100},
  publisher = {PMLR}
}

@inproceedings{Zhang2025VLBench,
  author    = {Zhang, Shiduo and Xu, Zhe and Liu, Peiju and Yu, Xiaopeng and Li, Yuan and Gao, Qinghui and Fei, Zhaoye and Yin, Zhangyue and Wu, Zuxuan and Jiang, Yu-Gang and {\textit{et al.}}},
  title     = {Vlabench: A large-scale benchmark for language-conditioned robotics manipulation with long-horizon reasoning tasks},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year      = {2025},
  pages     = {11142--11152},
  publisher = {IEEE}
}

@inproceedings{Li2023Behavior1K,
  author    = {Li, Chengshu and Zhang, Ruohan and Wong, Josiah and Gokmen, Cem and Srivastava, Sanjana and Mart{\'\i}n-Mart{\'\i}n, Roberto and Wang, Chen and Levine, Gabrael and Lingelbach, Michael and Sun, Jiankai and {\textit{et al.}}},
  title     = {Behavior-1k: A benchmark for embodied ai with 1,000 everyday activities and realistic simulation},
  booktitle = {Conference on Robot Learning},
  year      = {2023},
  pages     = {80--93},
  publisher = {PMLR}
}

@inproceedings{Paxton2023HomeRobot,
  author    = {Paxton, Chris and Wang, Austin and Shah, Binit and Matulevich, Blaine and Shah, Dhruv and Yadav, Karmesh and Ramakrishnan, Santhosh and Yenamandra, Sriram and Bisk, Yonatan},
  title     = {HomeRobot: An Open Source Software Stack for Mobile Manipulation Research},
  booktitle = {Proceedings of the AAAI Symposium Series},
  volume    = {2},
  number    = {1},
  pages     = {518--525},
  year      = {2023}
}

@misc{SC2017AIDevelopmentPlan,
  author       = {{\text{中华人民共和国国务院}}},
  title        = {{新一代人工智能发展规划}[EB/OL]},
  year         = {2017},
  howpublished = {\url{https://www.gov.cn/zhengce/content/2017-07/20/content_5211996.htm}},
  note         = {国发〔2017〕35号},
  language     = {zh}
}

@misc{MIIT2021RobotPlan,
  author       = {{\text{工业和信息化部等}}},
  title        = {{“十四五”机器人产业发展规划}[EB/OL]},
  year         = {2021},
  howpublished = {\url{https://www.gov.cn/zhengce/zhengceku/2021-12/28/content_5664988.htm}},
  note         = {工信部联规〔2021〕206号},
  language     = {zh}
}

@misc{MOE2018AIActionPlan,
  author       = {{\text{中华人民共和国教育部}}},
  title        = {{高等学校人工智能创新行动计划}[EB/OL]},
  year         = {2018},
  howpublished = {\url{http://www.moe.gov.cn/srcsite/A16/s7062/201804/t20180410_332722.html}},
  language     = {zh}
}

@online{Waymo2023TechBlog,
  author     = {{Waymo}},
  title      = {Waymo self-driving technology overview},
  year       = {2023},
  urldate    = {2025-11-13},
  url        = {https://waymo.com/tech/},
}

@online{Tesla2023FSDv12,
  author    = {Karpathy, Andrej and {Tesla Autopilot Team}},
  title     = {Tesla Full Self-Driving (FSD) v12 End-to-End Neural Network Architecture},
  year      = {2023},
  urldate   = {2025-11-13},
  url       = {https://www.tesla.com/AI},
}